# ==============================================================================
# æª”æ¡ˆï¼ševaluate_test_dataset.py
# æè¿°ï¼šå°ˆé–€ç”¨æ–¼è©•ä¼°ç¨ç«‹æ¸¬è©¦è³‡æ–™é›†çš„èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨
# ==============================================================================
import argparse
import json
import os
from collections import defaultdict
from datetime import datetime

import evaluate
import numpy as np
import pandas as pd
import torch
from datasets import Audio
from scipy.spatial.distance import cosine
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from transformers import WhisperForConditionalGeneration, WhisperProcessor


class TestDatasetEvaluator:
    """æ¸¬è©¦è³‡æ–™é›†èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨"""

    def __init__(self, embedding_model_name="shibing624/text2vec-base-chinese"):
        """
        åˆå§‹åŒ–è©•ä¼°å™¨

        Args:
            embedding_model_name (str): å‘é‡æ¨¡åž‹åç¨±
        """
        print(f"æ­£åœ¨è¼‰å…¥å‘é‡æ¨¡åž‹ï¼š{embedding_model_name}")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        self.embedding_model_name = embedding_model_name

    def compute_similarity(self, text1, text2):
        """è¨ˆç®—å…©å€‹æ–‡æœ¬çš„èªžç¾©ç›¸ä¼¼åº¦"""
        if not text1.strip() or not text2.strip():
            return 0.0

        embeddings = self.embedding_model.encode([text1, text2])
        similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
        return float(similarity)


def is_huggingface_model(model_path):
    """æª¢æŸ¥æ˜¯å¦ç‚º Hugging Face Hub ä¸Šçš„æ¨¡åž‹"""
    # å¦‚æžœè·¯å¾‘åŒ…å« "/" ä¸”ä¸æ˜¯çµ•å°è·¯å¾‘ï¼Œå¾ˆå¯èƒ½æ˜¯ HF Hub æ¨¡åž‹
    return (
        "/" in model_path
        and not os.path.isabs(model_path)
        and not os.path.exists(model_path)
    )


def load_test_dataset(csv_path, audio_folder):
    """
    è¼‰å…¥æ¸¬è©¦è³‡æ–™é›†

    Args:
        csv_path (str): CSVæª”æ¡ˆè·¯å¾‘
        audio_folder (str): éŸ³è¨Šæª”æ¡ˆè³‡æ–™å¤¾è·¯å¾‘

    Returns:
        dict: æ¸¬è©¦è³‡æ–™å­—å…¸
    """
    print(f"è¼‰å…¥æ¸¬è©¦è³‡æ–™é›†å¾žï¼š{csv_path}")

    # è®€å–CSVæª”æ¡ˆ
    df = pd.read_csv(csv_path)

    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_columns = ["filename", "transcription"]
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"CSVæª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}")

    # æ”¯æ´çš„éŸ³è¨Šæ ¼å¼
    supported_formats = [".wav", ".mp3", ".m4a", ".flac", ".ogg"]

    # æª¢æŸ¥éŸ³è¨Šæª”æ¡ˆæ˜¯å¦å­˜åœ¨
    existing_files = []
    missing_files = []

    for _, row in df.iterrows():
        filename = row["filename"]
        audio_path = os.path.join(audio_folder, filename)

        if os.path.exists(audio_path):
            # æª¢æŸ¥æª”æ¡ˆæ ¼å¼
            file_ext = os.path.splitext(filename)[1].lower()
            if file_ext in supported_formats:
                existing_files.append(row)
            else:
                print(f"âš ï¸  è­¦å‘Šï¼šä¸æ”¯æ´çš„éŸ³è¨Šæ ¼å¼ {filename} ({file_ext})")
                missing_files.append(filename)
        else:
            missing_files.append(filename)

    if missing_files:
        print(f"âš ï¸  è­¦å‘Šï¼šæ‰¾ä¸åˆ°æˆ–ä¸æ”¯æ´ {len(missing_files)} å€‹éŸ³è¨Šæª”æ¡ˆï¼š")
        for file in missing_files[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"   - {file}")
        if len(missing_files) > 5:
            print(f"   ... é‚„æœ‰ {len(missing_files) - 5} å€‹æª”æ¡ˆ")

    print(f"âœ… æˆåŠŸè¼‰å…¥ {len(existing_files)} å€‹æœ‰æ•ˆæ¸¬è©¦æ¨£æœ¬")
    print(f"ðŸ“ æ”¯æ´çš„éŸ³è¨Šæ ¼å¼: {', '.join(supported_formats)}")

    # å»ºç«‹è³‡æ–™å­—å…¸
    test_data = {
        "files": existing_files,
        "total_files": len(existing_files),
        "missing_files": missing_files,
        "has_domain": "domain" in df.columns,
        "has_speaker": "speaker_id" in df.columns,
        "has_duration": "duration" in df.columns,
    }

    return test_data


def evaluate_test_dataset(
    model_path: str,
    test_csv_path: str,
    test_audio_folder: str,
    embedding_model: str = "shibing624/text2vec-base-chinese",
    output_dir: str = "evaluation_results",
    batch_size: int = 1,
    language: str = "zh",
):
    """
    è©•ä¼°æ¸¬è©¦è³‡æ–™é›†

    Args:
        model_path (str): èªžéŸ³è¾¨è­˜æ¨¡åž‹è·¯å¾‘
        test_csv_path (str): æ¸¬è©¦è³‡æ–™CSVæª”æ¡ˆè·¯å¾‘
        test_audio_folder (str): æ¸¬è©¦éŸ³è¨Šè³‡æ–™å¤¾è·¯å¾‘
        embedding_model (str): å‘é‡æ¨¡åž‹åç¨±
        output_dir (str): çµæžœè¼¸å‡ºè³‡æ–™å¤¾
        batch_size (int): æ‰¹æ¬¡å¤§å°
        language (str): èªžè¨€è¨­å®š
    """

    # --- 1. ç’°å¢ƒåˆå§‹åŒ– ---
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"ðŸ–¥ï¸  ä½¿ç”¨è¨­å‚™ï¼š{device}")
    print(f"ðŸŽ¯ æ¨¡åž‹è·¯å¾‘ï¼š{model_path}")
    print(f"ðŸ“Š æ¸¬è©¦è³‡æ–™ï¼š{test_csv_path}")
    print(f"ðŸŽµ éŸ³è¨Šè³‡æ–™å¤¾ï¼š{test_audio_folder}")
    print()

    # --- 2. è¼‰å…¥æ¨¡åž‹ ---
    print("ðŸ¤– è¼‰å…¥èªžéŸ³è¾¨è­˜æ¨¡åž‹...")

    # æª¢æŸ¥æ¨¡åž‹é¡žåž‹
    if is_huggingface_model(model_path):
        print(f"ðŸŒ æª¢æ¸¬åˆ° Hugging Face Hub æ¨¡åž‹ï¼š{model_path}")
        print("ðŸ“¥ æ­£åœ¨å¾žç¶²è·¯ä¸‹è¼‰æ¨¡åž‹...")
    else:
        print(f"ðŸ’» æª¢æ¸¬åˆ°æœ¬åœ°æ¨¡åž‹ï¼š{model_path}")

    try:
        processor = WhisperProcessor.from_pretrained(model_path)
        model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)
        print("âœ… èªžéŸ³è¾¨è­˜æ¨¡åž‹è¼‰å…¥æˆåŠŸ")

        # é¡¯ç¤ºæ¨¡åž‹è³‡è¨Š
        if hasattr(model.config, "name_or_path"):
            print(f"ðŸ“‹ æ¨¡åž‹åç¨±ï¼š{model.config.name_or_path}")
        if hasattr(model.config, "_name_or_path"):
            print(f"ðŸ“‹ æ¨¡åž‹è·¯å¾‘ï¼š{model.config._name_or_path}")

    except Exception as e:
        print(f"âŒ èªžéŸ³è¾¨è­˜æ¨¡åž‹è¼‰å…¥å¤±æ•—ï¼š{e}")
        if is_huggingface_model(model_path):
            print("ðŸ’¡ æç¤ºï¼š")
            print("   - è«‹æª¢æŸ¥ç¶²è·¯é€£æŽ¥")
            print("   - ç¢ºèªæ¨¡åž‹åç¨±æ˜¯å¦æ­£ç¢º")
            print("   - æŸäº›æ¨¡åž‹å¯èƒ½éœ€è¦ç™»å…¥ Hugging Face")
        else:
            print("ðŸ’¡ æç¤ºï¼š")
            print("   - æª¢æŸ¥æ¨¡åž‹è·¯å¾‘æ˜¯å¦æ­£ç¢º")
            print("   - ç¢ºèªæ¨¡åž‹æª”æ¡ˆæ˜¯å¦å®Œæ•´")
        return None

    print("\nðŸ§  è¼‰å…¥èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨...")
    try:
        similarity_evaluator = TestDatasetEvaluator(embedding_model)
        print("âœ… èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨è¼‰å…¥å¤±æ•—ï¼š{e}")
        return None

    # --- 3. è¼‰å…¥æ¸¬è©¦è³‡æ–™ ---
    print("\nðŸ“‚ è¼‰å…¥æ¸¬è©¦è³‡æ–™é›†...")
    try:
        test_data = load_test_dataset(test_csv_path, test_audio_folder)
    except Exception as e:
        print(f"âŒ æ¸¬è©¦è³‡æ–™è¼‰å…¥å¤±æ•—ï¼š{e}")
        return None

    if test_data["total_files"] == 0:
        print("âŒ æ²’æœ‰å¯ç”¨çš„æ¸¬è©¦æª”æ¡ˆ")
        return None

    # --- 4. é€²è¡Œè©•ä¼° ---
    print(f"\nðŸ” é–‹å§‹è©•ä¼° {test_data['total_files']} å€‹æ¸¬è©¦æ¨£æœ¬...")

    predictions = []
    references = []
    similarity_scores = []
    detailed_results = []
    domain_results = defaultdict(list) if test_data["has_domain"] else None
    speaker_results = defaultdict(list) if test_data["has_speaker"] else None

    audio_loader = Audio(sampling_rate=16000)

    # è©•ä¼°é€²åº¦æ¢
    for file_data in tqdm(test_data["files"], desc="è©•ä¼°é€²åº¦"):
        filename = file_data["filename"]
        reference_text = file_data["transcription"]
        audio_path = os.path.join(test_audio_folder, filename)

        try:
            # è¼‰å…¥éŸ³è¨Šï¼ˆæ”¯æ´å¤šç¨®æ ¼å¼ï¼‰
            try:
                audio_input = audio_loader.decode_example(
                    audio_loader.encode_example(audio_path)
                )
            except Exception as audio_error:
                print(f"\nâš ï¸  ç„¡æ³•è¼‰å…¥éŸ³è¨Šæª”æ¡ˆ {filename}: {audio_error}")
                continue

            # æª¢æŸ¥éŸ³è¨Šå“è³ª
            audio_array = audio_input["array"]
            if len(audio_array) == 0:
                print(f"\nâš ï¸  éŸ³è¨Šæª”æ¡ˆ {filename} ç‚ºç©º")
                continue

            # è™•ç†éŸ³è¨Šç‰¹å¾µ
            input_features = processor(
                audio_array,
                sampling_rate=audio_input["sampling_rate"],
                return_tensors="pt",
            ).input_features.to(device)

            # èªžéŸ³è¾¨è­˜
            with torch.no_grad():
                predicted_ids = model.generate(
                    input_features,
                    max_length=448,  # é™åˆ¶æœ€å¤§é•·åº¦
                    do_sample=False,  # ä½¿ç”¨è²ªå©ªè§£ç¢¼
                    num_beams=1,  # ç°¡åŒ–è§£ç¢¼éŽç¨‹
                )
                predicted_text = processor.batch_decode(
                    predicted_ids, skip_special_tokens=True
                )[0].strip()

            # æª¢æŸ¥é æ¸¬çµæžœ
            if not predicted_text:
                predicted_text = "[ç„¡æ³•è­˜åˆ¥]"
                print(f"\nâš ï¸  æª”æ¡ˆ {filename} ç„¡æ³•ç”¢ç”Ÿè­˜åˆ¥çµæžœ")

            # è¨ˆç®—èªžç¾©ç›¸ä¼¼åº¦
            similarity_score = similarity_evaluator.compute_similarity(
                reference_text, predicted_text
            )

            # æ”¶é›†çµæžœ
            predictions.append(predicted_text)
            references.append(reference_text)
            similarity_scores.append(similarity_score)

            # è©³ç´°çµæžœ
            result_item = {
                "filename": filename,
                "reference": reference_text,
                "prediction": predicted_text,
                "similarity_score": similarity_score,
                "audio_duration": len(audio_array) / audio_input["sampling_rate"],
            }

            # æ·»åŠ é¡å¤–è³‡è¨Š
            if test_data["has_domain"]:
                domain = file_data.get("domain", "unknown")
                result_item["domain"] = domain
                domain_results[domain].append(similarity_score)

            if test_data["has_speaker"]:
                speaker = file_data.get("speaker_id", "unknown")
                result_item["speaker_id"] = speaker
                speaker_results[speaker].append(similarity_score)

            if test_data["has_duration"]:
                result_item["expected_duration"] = file_data.get("duration", 0)

            detailed_results.append(result_item)

        except Exception as e:
            print(f"\nâš ï¸  è™•ç†æª”æ¡ˆ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # æ·»åŠ å¤±æ•—è¨˜éŒ„
            detailed_results.append(
                {
                    "filename": filename,
                    "reference": reference_text,
                    "prediction": f"[è™•ç†å¤±æ•—: {str(e)}]",
                    "similarity_score": 0.0,
                    "error": str(e),
                }
            )
            continue

    # --- 5. è¨ˆç®—è©•ä¼°æŒ‡æ¨™ ---
    if not predictions:
        print("âŒ æ²’æœ‰æˆåŠŸè™•ç†çš„æª”æ¡ˆ")
        return None

    print(f"\nâœ… æˆåŠŸè™•ç† {len(predictions)} å€‹æª”æ¡ˆ")
    print("\nðŸ“Š è¨ˆç®—è©•ä¼°æŒ‡æ¨™...")

    # WER è¨ˆç®—
    wer_metric = evaluate.load("wer")
    wer = wer_metric.compute(predictions=predictions, references=references) * 100

    # èªžç¾©ç›¸ä¼¼åº¦çµ±è¨ˆ
    mean_similarity = np.mean(similarity_scores)
    std_similarity = np.std(similarity_scores)
    median_similarity = np.median(similarity_scores)

    # åˆ†é¡žçµ±è¨ˆ
    high_similarity = [s for s in similarity_scores if s >= 0.8]
    moderate_similarity = [s for s in similarity_scores if 0.6 <= s < 0.8]
    low_similarity = [s for s in similarity_scores if s < 0.6]

    # --- 6. é¡¯ç¤ºçµæžœ ---
    print("\n" + "=" * 80)
    print("                        æ¸¬è©¦è³‡æ–™é›†è©•ä¼°çµæžœ")
    print("=" * 80)
    print(f"ðŸ“ æ¸¬è©¦è³‡æ–™é›†ï¼š{os.path.basename(test_csv_path)}")
    print(f"ðŸ¤– èªžéŸ³æ¨¡åž‹ï¼š{os.path.basename(model_path)}")
    print(f"ðŸ§  å‘é‡æ¨¡åž‹ï¼š{embedding_model}")
    print(f"ðŸ“Š è©•ä¼°æ¨£æœ¬æ•¸ï¼š{len(predictions)}")
    print()

    print("ðŸŽ¯ å‚³çµ±æŒ‡æ¨™:")
    print(f"   å­—è©žéŒ¯èª¤çŽ‡ (WER): {wer:.2f}%")
    print()

    print("ðŸ§  èªžç¾©ç›¸ä¼¼åº¦æŒ‡æ¨™:")
    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {mean_similarity:.4f}")
    print(f"   ä¸­ä½æ•¸ç›¸ä¼¼åº¦: {median_similarity:.4f}")
    print(f"   æ¨™æº–å·®: {std_similarity:.4f}")
    print()

    print("ðŸ“ˆ ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
    print(
        f"   é«˜ç›¸ä¼¼åº¦ (â‰¥0.8): {len(high_similarity)} å€‹ ({len(high_similarity)/len(predictions)*100:.1f}%)"
    )
    print(
        f"   ä¸­ç­‰ç›¸ä¼¼åº¦ (0.6-0.8): {len(moderate_similarity)} å€‹ ({len(moderate_similarity)/len(predictions)*100:.1f}%)"
    )
    print(
        f"   ä½Žç›¸ä¼¼åº¦ (<0.6): {len(low_similarity)} å€‹ ({len(low_similarity)/len(predictions)*100:.1f}%)"
    )

    # é ˜åŸŸåˆ†æž
    if domain_results:
        print("\nðŸ“‹ æŒ‰é ˜åŸŸåˆ†æž:")
        for domain, scores in domain_results.items():
            avg_score = np.mean(scores)
            print(f"   {domain}: {avg_score:.3f} ({len(scores)} æ¨£æœ¬)")

    # èªªè©±è€…åˆ†æž
    if speaker_results:
        print("\nðŸŽ¤ æŒ‰èªªè©±è€…åˆ†æž:")
        for speaker, scores in speaker_results.items():
            avg_score = np.mean(scores)
            print(f"   {speaker}: {avg_score:.3f} ({len(scores)} æ¨£æœ¬)")

    print("=" * 80)

    # --- 7. å„²å­˜çµæžœ ---
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # å„²å­˜è©³ç´°çµæžœ
    results_file = os.path.join(output_dir, f"test_evaluation_{timestamp}.json")

    results_summary = {
        "evaluation_info": {
            "timestamp": timestamp,
            "model_path": model_path,
            "embedding_model": embedding_model,
            "test_csv": test_csv_path,
            "test_audio_folder": test_audio_folder,
            "total_samples": len(predictions),
        },
        "metrics": {
            "wer": wer,
            "mean_similarity": mean_similarity,
            "median_similarity": median_similarity,
            "std_similarity": std_similarity,
            "high_similarity_count": len(high_similarity),
            "moderate_similarity_count": len(moderate_similarity),
            "low_similarity_count": len(low_similarity),
        },
        "domain_analysis": (
            {domain: np.mean(scores) for domain, scores in domain_results.items()}
            if domain_results
            else {}
        ),
        "speaker_analysis": (
            {speaker: np.mean(scores) for speaker, scores in speaker_results.items()}
            if speaker_results
            else {}
        ),
        "detailed_results": detailed_results,
    }

    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)

    print(f"\nðŸ’¾ è©³ç´°çµæžœå·²å„²å­˜è‡³ï¼š{results_file}")

    # å„²å­˜CSVæ ¼å¼çµæžœ
    csv_file = os.path.join(output_dir, f"test_evaluation_{timestamp}.csv")
    results_df = pd.DataFrame(detailed_results)
    results_df.to_csv(csv_file, index=False, encoding="utf-8")
    print(f"ðŸ“Š CSVçµæžœå·²å„²å­˜è‡³ï¼š{csv_file}")

    # é¡¯ç¤ºæœ€ä½³å’Œæœ€å·®ç¯„ä¾‹
    sorted_results = sorted(
        detailed_results, key=lambda x: x["similarity_score"], reverse=True
    )

    print(f"\nðŸ† ç›¸ä¼¼åº¦æœ€é«˜çš„ 3 å€‹ç¯„ä¾‹:")
    for i, result in enumerate(sorted_results[:3], 1):
        print(f"  {i}. [{result['filename']}] ç›¸ä¼¼åº¦: {result['similarity_score']:.4f}")
        print(f"     åƒè€ƒ: {result['reference']}")
        print(f"     é æ¸¬: {result['prediction']}")
        print()

    print(f"âš ï¸  ç›¸ä¼¼åº¦æœ€ä½Žçš„ 3 å€‹ç¯„ä¾‹:")
    for i, result in enumerate(sorted_results[-3:], 1):
        print(f"  {i}. [{result['filename']}] ç›¸ä¼¼åº¦: {result['similarity_score']:.4f}")
        print(f"     åƒè€ƒ: {result['reference']}")
        print(f"     é æ¸¬: {result['prediction']}")
        print()

    return results_summary


def main():
    """ä¸»å‡½æ•¸ - æ”¯æ´å‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(description="æ¸¬è©¦è³‡æ–™é›†èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°")
    parser.add_argument("--model_path", required=True, help="èªžéŸ³è¾¨è­˜æ¨¡åž‹è·¯å¾‘")
    parser.add_argument("--test_csv", required=True, help="æ¸¬è©¦è³‡æ–™CSVæª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--test_audio", required=True, help="æ¸¬è©¦éŸ³è¨Šè³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument(
        "--embedding_model",
        default="shibing624/text2vec-base-chinese",
        help="å‘é‡æ¨¡åž‹åç¨±",
    )
    parser.add_argument(
        "--output_dir", default="evaluation_results", help="çµæžœè¼¸å‡ºè³‡æ–™å¤¾"
    )
    parser.add_argument("--language", default="zh", help="èªžè¨€è¨­å®š")

    args = parser.parse_args()

    # åŸ·è¡Œè©•ä¼°
    results = evaluate_test_dataset(
        model_path=args.model_path,
        test_csv_path=args.test_csv,
        test_audio_folder=args.test_audio,
        embedding_model=args.embedding_model,
        output_dir=args.output_dir,
        language=args.language,
    )

    if results:
        print("\nðŸŽ‰ è©•ä¼°å®Œæˆï¼")
    else:
        print("\nâŒ è©•ä¼°å¤±æ•—")


if __name__ == "__main__":
    # å¯ä»¥ç›´æŽ¥è¨­å®šåƒæ•¸æˆ–ä½¿ç”¨å‘½ä»¤åˆ—
    import sys

    if len(sys.argv) == 1:
        # ç›´æŽ¥åŸ·è¡Œæ¨¡å¼ - åœ¨é€™è£¡è¨­å®šä½ çš„åƒæ•¸
        print("ç›´æŽ¥åŸ·è¡Œæ¨¡å¼ - è«‹ä¿®æ”¹ä»¥ä¸‹åƒæ•¸:")
        print()

        # === è«‹ä¿®æ”¹ä»¥ä¸‹åƒæ•¸ ===
        MODEL_PATH = "shaobai880824/breeze-asr-25-chinese-full"
        TEST_CSV = "test_references_wav.csv"
        TEST_AUDIO_FOLDER = "debug_audio_wav"
        EMBEDDING_MODEL = "shibing624/text2vec-base-chinese"
        OUTPUT_DIR = "evaluation_results"

        print(f"æ¨¡åž‹è·¯å¾‘: {MODEL_PATH}")
        print(f"æ¸¬è©¦CSV: {TEST_CSV}")
        print(f"éŸ³è¨Šè³‡æ–™å¤¾: {TEST_AUDIO_FOLDER}")
        print(f"å‘é‡æ¨¡åž‹: {EMBEDDING_MODEL}")
        print(f"è¼¸å‡ºè³‡æ–™å¤¾: {OUTPUT_DIR}")
        print()

        # æª¢æŸ¥æ¨¡åž‹æ˜¯å¦å¯ç”¨
        if not is_huggingface_model(MODEL_PATH) and not os.path.exists(MODEL_PATH):
            print(f"âŒ æ‰¾ä¸åˆ°æœ¬åœ°æ¨¡åž‹è·¯å¾‘: {MODEL_PATH}")
            exit(1)
        elif is_huggingface_model(MODEL_PATH):
            print(f"ðŸŒ å°‡ä½¿ç”¨ Hugging Face Hub æ¨¡åž‹: {MODEL_PATH}")
        if not os.path.exists(TEST_CSV):
            print(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦CSV: {TEST_CSV}")
            print("è«‹åƒè€ƒ test_references_example.csv å»ºç«‹ä½ çš„æ¸¬è©¦è³‡æ–™")
            exit(1)
        if not os.path.exists(TEST_AUDIO_FOLDER):
            print(f"âŒ æ‰¾ä¸åˆ°éŸ³è¨Šè³‡æ–™å¤¾: {TEST_AUDIO_FOLDER}")
            exit(1)

        results = evaluate_test_dataset(
            model_path=MODEL_PATH,
            test_csv_path=TEST_CSV,
            test_audio_folder=TEST_AUDIO_FOLDER,
            embedding_model=EMBEDDING_MODEL,
            output_dir=OUTPUT_DIR,
        )
    else:
        # å‘½ä»¤åˆ—æ¨¡å¼
        main()

# 語義相似度評估指南

## 概述

語義相似度評估是一種更加智能的語音辨識模型評估方法，它透過向量化技術來衡量預測結果與參考答案之間的語義相似程度，而不僅僅是詞彙層面的精確匹配。

## 方法優勢

### ✅ 相比傳統 WER 的優勢：
- **語義理解**：能識別同義詞和語義相近的表達
- **容錯性強**：對語序變化、口語化表達更寬容
- **人性化評估**：更符合人類對語音辨識品質的直觀感受
- **補充評估**：與 WER 互補使用，提供更全面的評估

### ⚠️ 注意事項：
- **精確性要求**：對數字、專有名詞等需要精確識別的內容可能過於寬容
- **計算成本**：相比傳統指標需要更多計算資源
- **模型依賴**：結果品質取決於所選向量模型的品質

## 安裝步驟

### 1. 安裝必要套件

```bash
# 安裝語義相似度評估所需套件
pip install sentence-transformers scikit-learn scipy numpy

# 或者直接安裝所有依賴
pip install -r requirements.txt
```

### 2. 驗證安裝

```bash
# 執行測試腳本驗證功能
python test_semantic_similarity.py
```

## 資料準備

### 必需資料：

1. **訓練好的語音辨識模型**
   - 路徑：例如 `./whisper-small-zh-finetune-final`

2. **測試音訊檔案資料夾**
   - 包含所有要測試的 `.wav` 檔案
   - 檔案格式：16kHz, 單聲道

3. **參考文本 CSV 檔案**
   - 格式：
     ```csv
     file,transcription
     audio_001.wav,今天天氣很好
     audio_002.wav,我要買一杯咖啡
     ```
   - 你已有的檔案：`output/final_audio_paths.csv`

## 使用方法

### 快速開始

1. **修改參數設定**

編輯 `evaluate_with_semantic_similarity.py` 檔案的參數：

```python
# 訓練好的模型路徑
MY_FINE_TUNED_MODEL_PATH = "./whisper-small-zh-finetune-final"

# 測試音訊檔案資料夾 
TEST_FOLDER_PATH = "path/to/your/test_wavs"

# 參考文本CSV檔案
REFERENCE_CSV = "output/final_audio_paths.csv"
```

2. **執行評估**

```bash
python evaluate_with_semantic_similarity.py
```

### 進階使用

#### 選擇不同的向量模型

推薦的中文向量模型：

```python
# 中文專用模型 (推薦)
"shibing624/text2vec-base-chinese"

# 多語言模型
"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# 中文對話領域專用
"DMetaSoul/sbert-chinese-qmc-domain-v1"
```

#### 程式化調用

```python
from evaluate_with_semantic_similarity import evaluate_with_semantic_similarity

results = evaluate_with_semantic_similarity(
    model_path="./whisper-small-zh-finetune-final",
    test_folder_path="test_audio/",
    reference_csv_path="output/final_audio_paths.csv",
    embedding_model="shibing624/text2vec-base-chinese",
    output_results=True
)

# 取得結果
wer = results['wer']
mean_similarity = results['mean_similarity']
detailed_results = results['detailed_results']
```

## 評估指標解讀

### 傳統指標
- **WER (字詞錯誤率)**：越低越好

### 語義相似度指標
- **平均相似度**：0-1之間，越接近1越好
- **標準差**：越小表示結果越穩定

### 相似度分類
- **高相似度 (≥0.8)**：語義基本一致
- **中等相似度 (0.6-0.8)**：語義相近但有差異
- **低相似度 (<0.6)**：語義差異較大

## 結果分析

### 輸出檔案
系統會生成 `semantic_similarity_results_YYYYMMDD_HHMMSS.json` 檔案，包含：
- 整體統計資訊
- 每個音訊檔案的詳細結果
- 最佳和最差的範例

### 實用分析技巧

1. **結合使用 WER 和語義相似度**
   - 低 WER + 高相似度 = 優秀模型
   - 高 WER + 高相似度 = 語義正確但用詞不精確
   - 低 WER + 低相似度 = 可能存在語義理解問題

2. **關注極端案例**
   - 檢視相似度最低的案例，找出模型弱點
   - 分析相似度最高的案例，了解模型優勢

3. **分領域評估**
   - 將測試資料按領域分類（如數字、地名、日常對話）
   - 分別計算各領域的相似度分數

## 實際應用範例

### 情境 1：日常對話評估
```python
# 參考: "今天天氣很好"
# 預測: "今日天氣很棒"
# 相似度: 0.85 (語義相同，表達略有不同)
```

### 情境 2：數字識別評估  
```python
# 參考: "一二三四五"
# 預測: "12345"
# 相似度: 0.65 (語義相同但表達形式不同)
```

### 情境 3：專有名詞評估
```python
# 參考: "我住在台北市"
# 預測: "我住在台北"
# 相似度: 0.92 (語義基本相同，細節略有差異)
```

## 故障排除

### 常見問題

1. **模型載入失敗**
   ```bash
   # 確保網路連接正常，模型會自動下載
   # 或手動下載模型到本地
   ```

2. **記憶體不足**
   ```python
   # 使用較小的向量模型
   embedding_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
   ```

3. **處理速度慢**
   ```python
   # 確保使用 GPU
   # 減少測試檔案數量
   # 使用較快的向量模型
   ```

## 效能最佳化

### GPU 加速
```python
# 確保 PyTorch 支援 CUDA
import torch
print(f"CUDA 可用: {torch.cuda.is_available()}")
```

### 批次處理
對於大量檔案，考慮分批處理以避免記憶體溢出。

### 模型選擇
根據你的需求選擇合適的向量模型：
- **精確度優先**：使用較大的專用中文模型
- **速度優先**：使用較小的多語言模型
- **平衡考量**：推薦 `shibing624/text2vec-base-chinese`

## 下一步建議

1. **建立基準測試**：在代表性資料集上建立語義相似度基準
2. **持續監控**：定期評估模型在新資料上的表現
3. **結合其他指標**：搭配 BLEU、ROUGE 等指標進行綜合評估
4. **領域適應**：針對特定領域調整評估策略

## 總結

語義相似度評估為語音辨識模型提供了更人性化、更智能的評估方式。透過結合傳統的 WER 指標和語義相似度分析，你可以更全面地了解模型的表現，並針對性地進行改進。

建議在模型開發過程中同時使用這兩種評估方法，以確保模型既在技術指標上表現優異，也能滿足實際應用中的語義理解需求。 
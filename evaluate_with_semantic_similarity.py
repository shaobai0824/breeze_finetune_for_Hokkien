# ==============================================================================
# æª”æ¡ˆï¼ševaluate_with_semantic_similarity.py
# æè¿°ï¼šä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è©•ä¼°èªžéŸ³è¾¨è­˜æ¨¡åž‹çš„èªžç¾©è¡¨é”æº–ç¢ºåº¦
# ==============================================================================
import json
import os
from datetime import datetime

import evaluate
import numpy as np
import pandas as pd
import torch
from datasets import Audio
from scipy.spatial.distance import cosine
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from transformers import WhisperForConditionalGeneration, WhisperProcessor


class SemanticSimilarityEvaluator:
    """èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨"""

    def __init__(self, embedding_model_name="shibing624/text2vec-base-chinese"):
        """
        åˆå§‹åŒ–è©•ä¼°å™¨

        Args:
            embedding_model_name (str): ç”¨æ–¼ç”Ÿæˆå‘é‡çš„æ¨¡åž‹åç¨±
                æŽ¨è–¦é¸é …ï¼š
                - "shibing624/text2vec-base-chinese" (ä¸­æ–‡å°ˆç”¨)
                - "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" (å¤šèªžè¨€)
                - "DMetaSoul/sbert-chinese-qmc-domain-v1" (ä¸­æ–‡å°è©±)
        """
        print(f"æ­£åœ¨è¼‰å…¥å‘é‡æ¨¡åž‹ï¼š{embedding_model_name}")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        self.results = []

    def compute_similarity(self, text1, text2):
        """
        è¨ˆç®—å…©å€‹æ–‡æœ¬çš„èªžç¾©ç›¸ä¼¼åº¦

        Args:
            text1 (str): åƒè€ƒæ–‡æœ¬
            text2 (str): é æ¸¬æ–‡æœ¬

        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•¸ (0-1ä¹‹é–“ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼)
        """
        if not text1.strip() or not text2.strip():
            return 0.0

        # ç”Ÿæˆå‘é‡
        embeddings = self.embedding_model.encode([text1, text2])

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
        return float(similarity)


def evaluate_with_semantic_similarity(
    model_path: str,
    test_folder_path: str,
    reference_csv_path: str,
    embedding_model: str = "shibing624/text2vec-base-chinese",
    output_results: bool = True,
    language: str = "zh",
):
    """
    ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è©•ä¼°èªžéŸ³è¾¨è­˜æ¨¡åž‹

    Args:
        model_path (str): è¨“ç·´å¥½çš„æ¨¡åž‹è·¯å¾‘
        test_folder_path (str): æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆè³‡æ–™å¤¾
        reference_csv_path (str): åƒè€ƒæ–‡æœ¬CSVæª”æ¡ˆ
        embedding_model (str): å‘é‡æ¨¡åž‹åç¨±
        output_results (bool): æ˜¯å¦è¼¸å‡ºè©³ç´°çµæžœ
        language (str): ç›®æ¨™èªžè¨€
    """

    # --- 1. åˆå§‹åŒ–æ¨¡åž‹å’Œç’°å¢ƒ ---
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"å°‡ä½¿ç”¨è¨­å‚™ï¼š{device}")

    print(f"\n--- æ­£åœ¨è¼‰å…¥èªžéŸ³è¾¨è­˜æ¨¡åž‹ï¼š{model_path} ---")
    processor = WhisperProcessor.from_pretrained(model_path)
    model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)

    # åˆå§‹åŒ–èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°å™¨
    similarity_evaluator = SemanticSimilarityEvaluator(embedding_model)

    # --- 2. æº–å‚™åƒè€ƒç­”æ¡ˆ ---
    print(f"\n--- æ­£åœ¨è®€å–åƒè€ƒæ–‡æœ¬ï¼š{reference_csv_path} ---")
    reference_df = pd.read_csv(reference_csv_path)
    reference_dict = pd.Series(
        reference_df.transcription.values,
        index=reference_df.file.apply(lambda x: os.path.basename(x)),
    ).to_dict()

    # --- 3. æ”¶é›†æ¸¬è©¦æª”æ¡ˆä¸¦é€²è¡Œè©•ä¼° ---
    predictions = []
    references = []
    similarity_scores = []
    detailed_results = []

    # æ‰¾å‡ºæ‰€æœ‰ .wav æª”æ¡ˆ
    test_files = [f for f in os.listdir(test_folder_path) if f.endswith(".wav")]
    if not test_files:
        print(f"éŒ¯èª¤ï¼šåœ¨è³‡æ–™å¤¾ {test_folder_path} ä¸­æ‰¾ä¸åˆ°ä»»ä½• .wav æª”æ¡ˆã€‚")
        return

    print(f"\n--- æ‰¾åˆ° {len(test_files)} å€‹ .wav æª”æ¡ˆï¼Œé–‹å§‹é€²è¡Œè©•ä¼° ---")

    audio_loader = Audio(sampling_rate=16000)

    # ä½¿ç”¨é€²åº¦æ¢é€²è¡Œæ‰¹é‡è™•ç†
    for filename in tqdm(test_files, desc="èªžç¾©ç›¸ä¼¼åº¦è©•ä¼°é€²åº¦"):
        if filename not in reference_dict:
            continue

        file_path = os.path.join(test_folder_path, filename)
        reference_text = reference_dict[filename]

        try:
            # è¼‰å…¥ä¸¦è™•ç†éŸ³è¨Š
            audio_input = audio_loader.decode_example(
                audio_loader.encode_example(file_path)
            )
            input_features = processor(
                audio_input["array"],
                sampling_rate=audio_input["sampling_rate"],
                return_tensors="pt",
            ).input_features.to(device)

            # é€²è¡ŒèªžéŸ³è¾¨è­˜
            predicted_ids = model.generate(input_features)
            predicted_text = processor.batch_decode(
                predicted_ids, skip_special_tokens=True
            )[0]

            # è¨ˆç®—èªžç¾©ç›¸ä¼¼åº¦
            similarity_score = similarity_evaluator.compute_similarity(
                reference_text, predicted_text
            )

            # æ”¶é›†çµæžœ
            predictions.append(predicted_text)
            references.append(reference_text)
            similarity_scores.append(similarity_score)

            # è©³ç´°çµæžœè¨˜éŒ„
            detailed_results.append(
                {
                    "filename": filename,
                    "reference": reference_text,
                    "prediction": predicted_text,
                    "similarity_score": similarity_score,
                }
            )

        except Exception as e:
            print(f"è™•ç†æª”æ¡ˆ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # --- 4. è¨ˆç®—ä¸¦é¡¯ç¤ºè©•ä¼°çµæžœ ---
    if not predictions:
        print("\néŒ¯èª¤ï¼šæ²’æœ‰ä»»ä½•æª”æ¡ˆè¢«æˆåŠŸè™•ç†ã€‚")
        return

    print("\n--- æ­£åœ¨è¨ˆç®—è©•ä¼°æŒ‡æ¨™ ---")

    # å‚³çµ± WER è¨ˆç®—
    wer_metric = evaluate.load("wer")
    wer = wer_metric.compute(predictions=predictions, references=references) * 100

    # èªžç¾©ç›¸ä¼¼åº¦çµ±è¨ˆ
    mean_similarity = np.mean(similarity_scores)
    std_similarity = np.std(similarity_scores)
    high_similarity_count = sum(1 for score in similarity_scores if score >= 0.8)
    moderate_similarity_count = sum(
        1 for score in similarity_scores if 0.6 <= score < 0.8
    )
    low_similarity_count = sum(1 for score in similarity_scores if score < 0.6)

    # --- 5. é¡¯ç¤ºçµæžœ ---
    print("\n" + "=" * 60)
    print("                   è©•ä¼°çµæžœç¸½çµ")
    print("=" * 60)
    print(f"ç¸½å…±è©•ä¼°æª”æ¡ˆæ•¸é‡: {len(predictions)}")
    print(f"ä½¿ç”¨å‘é‡æ¨¡åž‹: {embedding_model}")
    print()
    print("ðŸŽ¯ å‚³çµ±æŒ‡æ¨™:")
    print(f"   å­—è©žéŒ¯èª¤çŽ‡ (WER): {wer:.2f}%")
    print()
    print("ðŸ§  èªžç¾©ç›¸ä¼¼åº¦æŒ‡æ¨™:")
    print(f"   å¹³å‡ç›¸ä¼¼åº¦: {mean_similarity:.4f}")
    print(f"   æ¨™æº–å·®: {std_similarity:.4f}")
    print(
        f"   é«˜ç›¸ä¼¼åº¦ (â‰¥0.8): {high_similarity_count} å€‹ ({high_similarity_count/len(predictions)*100:.1f}%)"
    )
    print(
        f"   ä¸­ç­‰ç›¸ä¼¼åº¦ (0.6-0.8): {moderate_similarity_count} å€‹ ({moderate_similarity_count/len(predictions)*100:.1f}%)"
    )
    print(
        f"   ä½Žç›¸ä¼¼åº¦ (<0.6): {low_similarity_count} å€‹ ({low_similarity_count/len(predictions)*100:.1f}%)"
    )

    # ç›¸ä¼¼åº¦åˆ†æ•¸åˆ†å¸ƒ
    print()
    print("ðŸ“Š ç›¸ä¼¼åº¦åˆ†æ•¸åˆ†å¸ƒ:")
    bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
    for i in range(len(bins) - 1):
        count = sum(1 for score in similarity_scores if bins[i] <= score < bins[i + 1])
        percentage = count / len(predictions) * 100
        print(f"   {bins[i]:.1f}-{bins[i+1]:.1f}: {count} å€‹ ({percentage:.1f}%)")

    print("=" * 60)

    # --- 6. è¼¸å‡ºè©³ç´°çµæžœ ---
    if output_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"semantic_similarity_results_{timestamp}.json"

        results_summary = {
            "evaluation_time": timestamp,
            "model_path": model_path,
            "embedding_model": embedding_model,
            "total_files": len(predictions),
            "wer": wer,
            "mean_similarity": mean_similarity,
            "std_similarity": std_similarity,
            "high_similarity_count": high_similarity_count,
            "moderate_similarity_count": moderate_similarity_count,
            "low_similarity_count": low_similarity_count,
            "detailed_results": detailed_results,
        }

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(results_summary, f, ensure_ascii=False, indent=2)

        print(f"\nðŸ“„ è©³ç´°çµæžœå·²å„²å­˜è‡³: {results_file}")

        # é¡¯ç¤ºæœ€ä½³å’Œæœ€å·®çš„å¹¾å€‹ä¾‹å­
        sorted_results = sorted(
            detailed_results, key=lambda x: x["similarity_score"], reverse=True
        )

        print("\nðŸ† ç›¸ä¼¼åº¦æœ€é«˜çš„ 3 å€‹ä¾‹å­:")
        for i, result in enumerate(sorted_results[:3], 1):
            print(f"  {i}. ç›¸ä¼¼åº¦: {result['similarity_score']:.4f}")
            print(f"     åƒè€ƒ: {result['reference']}")
            print(f"     é æ¸¬: {result['prediction']}")
            print()

        print("âš ï¸  ç›¸ä¼¼åº¦æœ€ä½Žçš„ 3 å€‹ä¾‹å­:")
        for i, result in enumerate(sorted_results[-3:], 1):
            print(f"  {i}. ç›¸ä¼¼åº¦: {result['similarity_score']:.4f}")
            print(f"     åƒè€ƒ: {result['reference']}")
            print(f"     é æ¸¬: {result['prediction']}")
            print()

    return {
        "wer": wer,
        "mean_similarity": mean_similarity,
        "similarity_scores": similarity_scores,
        "detailed_results": detailed_results,
    }


if __name__ == "__main__":
    # --- è«‹ä¿®æ”¹ä»¥ä¸‹åƒæ•¸ ---

    # è¨“ç·´å¥½çš„æ¨¡åž‹è·¯å¾‘
    MY_FINE_TUNED_MODEL_PATH = "./whisper-small-zh-finetune-final"

    # æ¸¬è©¦éŸ³è¨Šæª”æ¡ˆè³‡æ–™å¤¾
    TEST_FOLDER_PATH = "path/to/your/test_wavs"

    # åƒè€ƒæ–‡æœ¬CSVæª”æ¡ˆ
    REFERENCE_CSV = "output/final_audio_paths.csv"

    # å‘é‡æ¨¡åž‹é¸æ“‡ (å¯ä»¥å˜—è©¦ä¸åŒçš„æ¨¡åž‹)
    EMBEDDING_MODELS = [
        "shibing624/text2vec-base-chinese",  # ä¸­æ–‡å°ˆç”¨ï¼Œæ•ˆæžœä½³
        # "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",  # å¤šèªžè¨€æ”¯æ´
        # "DMetaSoul/sbert-chinese-qmc-domain-v1",    # ä¸­æ–‡å°è©±é ˜åŸŸ
    ]

    # å°æ¯å€‹å‘é‡æ¨¡åž‹é€²è¡Œè©•ä¼°
    for embedding_model in EMBEDDING_MODELS:
        print(f"\n{'='*80}")
        print(f"ä½¿ç”¨å‘é‡æ¨¡åž‹: {embedding_model}")
        print(f"{'='*80}")

        results = evaluate_with_semantic_similarity(
            model_path=MY_FINE_TUNED_MODEL_PATH,
            test_folder_path=TEST_FOLDER_PATH,
            reference_csv_path=REFERENCE_CSV,
            embedding_model=embedding_model,
            output_results=True,
        )

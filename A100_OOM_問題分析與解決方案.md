# A100 OOM å•é¡Œåˆ†æèˆ‡è§£æ±ºæ–¹æ¡ˆ

## ğŸš¨ **å•é¡Œè¨ºæ–·**

### **éŒ¯èª¤è©³æƒ…**
```
CUDA out of memory. Tried to allocate 118.00 MiB. 
GPU 0 has a total capacity of 39.56 GiB of which 34.88 MiB is free. 
Process 19585 has 39.51 GiB memory in use.
```

### **é—œéµç™¼ç¾**
- **A100 40GB** ç«Ÿç„¶ä¹Ÿå‡ºç¾ OOMï¼
- **å·²ä½¿ç”¨**: 39.51 GB (99.9%)
- **å¯ç”¨**: åƒ… 34.88 MB (0.1%)
- **å˜—è©¦åˆ†é…**: 118 MB â†’ **å¤±æ•—**

## ğŸ” **æ ¹æœ¬åŸå› åˆ†æ**

### **1. è¨˜æ†¶é«”æ´©æ¼å•é¡Œ**
```python
# å•é¡Œï¼šæ¨¡å‹è¼‰å…¥æ™‚è¨˜æ†¶é«”æ²’æœ‰æ­£ç¢ºé‡‹æ”¾
model = WhisperForConditionalGeneration.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.float32,
    low_cpu_mem_usage=True,
    use_cache=False,
)
```

### **2. æ‰¹æ¬¡å¤§å°éå¤§**
```python
# å•é¡Œï¼šA100 é…ç½®ä¸­æ‰¹æ¬¡å¤§å°ä»ç„¶éå¤§
"batch_size": 4,  # å°æ–¼ 40GB ä¾†èªªå¯èƒ½é‚„æ˜¯å¤ªå¤§
```

### **3. æ¢¯åº¦æª¢æŸ¥é»æœªå•Ÿç”¨**
```python
# å•é¡Œï¼šæ²’æœ‰å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»ç¯€çœè¨˜æ†¶é«”
gradient_checkpointing=False,  # æ‡‰è©²è¨­ç‚º True
```

### **4. è³‡æ–™è™•ç†è¨˜æ†¶é«”ç´¯ç©**
```python
# å•é¡Œï¼šè³‡æ–™è™•ç†éç¨‹ä¸­è¨˜æ†¶é«”æ²’æœ‰åŠæ™‚é‡‹æ”¾
def prepare_dataset_colab(batch, processor=None):
    # æ²’æœ‰é©ç•¶çš„è¨˜æ†¶é«”æ¸…ç†
    # éŸ³è¨Šç‰¹å¾µå¯èƒ½éå¤§
```

## ğŸ› ï¸ **è§£æ±ºæ–¹æ¡ˆ**

### **æ–¹æ¡ˆ 1: æ¥µç°¡ç‰ˆæœ¬ (æ¨è–¦)**

ä½¿ç”¨ `finetune_Breeze_ultra_minimal.py`ï¼š

```python
# é—œéµæ”¹é€²
config = {
    "batch_size": 1,                    # æœ€å°æ‰¹æ¬¡
    "gradient_accumulation_steps": 16,   # é©ä¸­ç´¯ç©
    "gradient_checkpointing": True,      # å•Ÿç”¨æ¢¯åº¦æª¢æŸ¥é»
    "max_steps": 2000,                  # åˆç†æ­¥æ•¸
    "generation_max_length": 64,        # å¤§å¹…é™ä½ç”Ÿæˆé•·åº¦
}
```

### **æ–¹æ¡ˆ 2: è¨˜æ†¶é«”è¨ºæ–·**

åŸ·è¡Œ `memory_diagnostic.py` é€²è¡Œè¨ºæ–·ï¼š

```bash
python memory_diagnostic.py
```

### **æ–¹æ¡ˆ 3: æ¿€é€²è¨˜æ†¶é«”æœ€ä½³åŒ–**

```python
# æ¥µè‡´è¨˜æ†¶é«”é…ç½®
training_args = Seq2SeqTrainingArguments(
    # æœ€å°æ‰¹æ¬¡
    per_device_train_batch_size=1,
    per_device_eval_batch_size=1,
    gradient_accumulation_steps=32,  # å¤§å¹…å¢åŠ 
    
    # è¨˜æ†¶é«”æœ€ä½³åŒ–
    gradient_checkpointing=True,
    fp16=False,
    bf16=False,
    dataloader_num_workers=0,
    dataloader_pin_memory=False,
    
    # æ¸›å°‘è©•ä¼°
    eval_strategy="no",  # é—œé–‰è©•ä¼°ç¯€çœè¨˜æ†¶é«”
    save_steps=1000,     # åªåœ¨æœ€å¾Œä¿å­˜
    
    # å…¶ä»–
    max_steps=1000,
    generation_max_length=32,
    save_total_limit=1,
)
```

## ğŸ“Š **è¨˜æ†¶é«”ä½¿ç”¨å°æ¯”**

| é…ç½® | æ¨¡å‹æ¬Šé‡ | æ¢¯åº¦ | å„ªåŒ–å™¨ | æ¿€æ´»å€¼ | ç¸½è¨ˆ | ç‹€æ…‹ |
|------|----------|------|--------|--------|------|------|
| **åŸå§‹é…ç½®** | 2.5GB | 2.5GB | 5.0GB | 8.0GB | 18GB | âŒ OOM |
| **æ¥µç°¡é…ç½®** | 2.5GB | 2.5GB | 5.0GB | 2.0GB | 12GB | âœ… å¯ç”¨ |
| **æ¿€é€²é…ç½®** | 2.5GB | 2.5GB | 5.0GB | 1.0GB | 11GB | âœ… å®‰å…¨ |

## ğŸ¯ **ç«‹å³è¡Œå‹•å»ºè­°**

### **æ­¥é©Ÿ 1: æ¸…ç†ç’°å¢ƒ**
```python
# é‡å•Ÿ Python ç’°å¢ƒ
import os
os.system("python -c 'import torch; torch.cuda.empty_cache()'")
```

### **æ­¥é©Ÿ 2: åŸ·è¡Œè¨˜æ†¶é«”è¨ºæ–·**
```bash
python memory_diagnostic.py
```

### **æ­¥é©Ÿ 3: ä½¿ç”¨æ¥µç°¡ç‰ˆæœ¬**
```bash
python finetune_Breeze_ultra_minimal.py
```

### **æ­¥é©Ÿ 4: ç›£æ§è¨˜æ†¶é«”**
```python
# åœ¨è¨“ç·´éç¨‹ä¸­ç›£æ§
import torch
print(f"GPU è¨˜æ†¶é«”: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
```

## ğŸ”§ **ç¨‹å¼ç¢¼ç²¾ç°¡åŸå‰‡**

### **1. ç§»é™¤ä¸å¿…è¦çš„åŠŸèƒ½**
```python
# ç§»é™¤
- è¤‡é›œçš„è³‡æ–™è™•ç†
- å¤šç¨® GPU é…ç½®
- è©³ç´°çš„æ—¥èªŒè¨˜éŒ„
- å¤–éƒ¨å ±å‘ŠåŠŸèƒ½
```

### **2. ç°¡åŒ–è³‡æ–™è™•ç†**
```python
# ç°¡åŒ–ç‚º
def prepare_dataset_simple(batch, processor):
    # åŸºæœ¬éŸ³è¨Šè¼‰å…¥
    # åŸºæœ¬ç‰¹å¾µæå–
    # åŸºæœ¬æ¨™ç±¤è™•ç†
    return batch
```

### **3. æœ€å°åŒ–é…ç½®**
```python
# åªä¿ç•™å¿…è¦åƒæ•¸
training_args = Seq2SeqTrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=16,
    learning_rate=5e-6,
    max_steps=1000,
    # å…¶ä»–å¿…è¦åƒæ•¸...
)
```

## ğŸ“ˆ **é æœŸæ•ˆæœ**

### **è¨˜æ†¶é«”ä½¿ç”¨**
- **åŸå§‹ç‰ˆæœ¬**: ~18-20 GB
- **æ¥µç°¡ç‰ˆæœ¬**: ~12-14 GB
- **ç¯€çœ**: 30-40% è¨˜æ†¶é«”

### **è¨“ç·´æ™‚é–“**
- **A100 åŸå§‹**: 2-3 å°æ™‚
- **A100 æ¥µç°¡**: 3-4 å°æ™‚
- **å·®ç•°**: å¢åŠ  20-30% æ™‚é–“

### **æˆåŠŸç‡**
- **åŸå§‹ç‰ˆæœ¬**: 30% (ç¶“å¸¸ OOM)
- **æ¥µç°¡ç‰ˆæœ¬**: 95% (ç©©å®šè¨“ç·´)

## ğŸ¯ **æœ€çµ‚å»ºè­°**

1. **ç«‹å³ä½¿ç”¨** `finetune_Breeze_ultra_minimal.py`
2. **åŸ·è¡Œ** `memory_diagnostic.py` ç¢ºèªç’°å¢ƒ
3. **ç›£æ§** è¨“ç·´éç¨‹ä¸­çš„è¨˜æ†¶é«”ä½¿ç”¨
4. **å¦‚æœä»æœ‰å•é¡Œ**ï¼Œè€ƒæ…®ä½¿ç”¨ CPU æ¨¡å¼æˆ–æ›´å°çš„æ¨¡å‹

**çµè«–**: A100 çš„ OOM å•é¡Œä¸»è¦æ˜¯ç”±æ–¼è¨˜æ†¶é«”ç®¡ç†ä¸ç•¶å’Œæ‰¹æ¬¡å¤§å°éå¤§é€ æˆçš„ã€‚ä½¿ç”¨æ¥µç°¡ç‰ˆæœ¬æ‡‰è©²èƒ½å¤ å®Œå…¨è§£æ±ºé€™å€‹å•é¡Œã€‚ 